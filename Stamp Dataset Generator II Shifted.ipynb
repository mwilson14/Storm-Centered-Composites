{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d840fdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\xarray\\core\\pycompat.py:22: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  duck_array_version = LooseVersion(duck_array_module.__version__)\n",
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\xarray\\core\\pycompat.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  duck_array_version = LooseVersion(\"0.0.0\")\n",
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\xarray\\core\\pycompat.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  duck_array_version = LooseVersion(\"0.0.0\")\n",
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\setuptools\\_distutils\\version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\setuptools\\_distutils\\version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\xarray\\core\\npcompat.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) >= \"1.20.0\":\n",
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\setuptools\\_distutils\\version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\xarray\\core\\pdcompat.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pd.__version__) < \"0.25.0\":\n",
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\setuptools\\_distutils\\version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    }
   ],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy.ma as ma\n",
    "from cartopy.io.shapereader import Reader\n",
    "from cartopy.feature import ShapelyFeature\n",
    "import pyart\n",
    "import matplotlib.lines as mlines\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from metpy.interpolate.grid import natural_neighbor_to_grid\n",
    "from metpy.interpolate import interpolate_to_points\n",
    "from metpy.interpolate import interpolate_to_grid\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "429004bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2017 thunderhoser\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "import numpy\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "def _run_pmm_one_variable(\n",
    "        input_matrix, max_percentile_level=100):\n",
    "    \"\"\"Applies PMM to one variable.\n",
    "    E = number of examples (realizations over which to average)\n",
    "    :param input_matrix: numpy array.  The first axis must have length E.  Other\n",
    "        axes are assumed to be spatial dimensions.  Thus, input_matrix[i, ...]\n",
    "        is the spatial field for the [i]th example.\n",
    "    :param max_percentile_level: Maximum percentile.  No output value will\n",
    "        exceed the [q]th percentile of `input_matrix`, where q =\n",
    "        `max_percentile_level`.  Similarly, no output value will be less than\n",
    "        the [100 - q]th percentile of `input_matrix`.\n",
    "    :return: mean_field_matrix: numpy array of probability-matched means.  Will\n",
    "        have the same dimensions as `input_matrix`, except without the first\n",
    "        axis.  For example, if `input_matrix` is E x 32 x 32 x 12, this will be\n",
    "        32 x 32 x 12.\n",
    "    \"\"\"\n",
    "\n",
    "    # Pool values over all dimensions and remove extremes.\n",
    "    pooled_values = numpy.ravel(input_matrix)\n",
    "    pooled_values = numpy.sort(pooled_values)\n",
    "\n",
    "    max_pooled_value = numpy.percentile(pooled_values, max_percentile_level)\n",
    "    pooled_values = pooled_values[pooled_values <= max_pooled_value]\n",
    "\n",
    "    min_pooled_value = numpy.percentile(\n",
    "        pooled_values, 100 - max_percentile_level)\n",
    "    pooled_values = pooled_values[pooled_values >= min_pooled_value]\n",
    "\n",
    "    # Find ensemble mean at each grid point.\n",
    "    mean_field_matrix = numpy.mean(input_matrix, axis=0)\n",
    "    mean_field_flattened = numpy.ravel(mean_field_matrix)\n",
    "\n",
    "    # At each grid point, replace ensemble mean with the same percentile from\n",
    "    # pooled array.\n",
    "    pooled_value_percentiles = numpy.linspace(\n",
    "        0, 100, num=len(pooled_values), dtype=float)\n",
    "    mean_value_percentiles = numpy.linspace(\n",
    "        0, 100, num=len(mean_field_flattened), dtype=float)\n",
    "\n",
    "    sort_indices = numpy.argsort(mean_field_flattened)\n",
    "    unsort_indices = numpy.argsort(sort_indices)\n",
    "\n",
    "    interp_object = interp1d(\n",
    "        pooled_value_percentiles, pooled_values, kind='linear',\n",
    "        bounds_error=True, assume_sorted=True)\n",
    "\n",
    "    mean_field_flattened = interp_object(mean_value_percentiles)\n",
    "    mean_field_flattened = mean_field_flattened[unsort_indices]\n",
    "    mean_field_matrix = numpy.reshape(\n",
    "        mean_field_flattened, mean_field_matrix.shape)\n",
    "\n",
    "    return mean_field_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "641d1f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rotation code from https://stackoverflow.com/questions/29708840/rotate-meshgrid-with-numpy\n",
    "def DoRotation(xspan, yspan, RotRad=0):\n",
    "    \"\"\"Generate a meshgrid and rotate it by RotRad radians.\"\"\"\n",
    "\n",
    "    # Clockwise, 2D rotation matrix\n",
    "    RotMatrix = np.array([[np.cos(RotRad),  np.sin(RotRad)],\n",
    "                          [-np.sin(RotRad), np.cos(RotRad)]])\n",
    "\n",
    "    x, y = np.meshgrid(xspan, yspan)\n",
    "    return np.einsum('ji, mni -> jmn', RotMatrix, np.dstack([x, y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26bd4f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -1 2021    6   19    0  220]\n",
      "['KIND' '2021' '6' '19' '0' '220']\n",
      "[220 160 190 145 200 140 160 180 110 170 120 170 165 140 150 140 140 170\n",
      " 170 150 150 130 150 130 140 190 180 180 180 180 130  70 170 200 200 190\n",
      " 190 120 130 140 200 200 180 220 190 180 190 160 160 150 160 150 160 180\n",
      " 140 150 140 170 150 160 180 180 210 230 190 230 180 180 150 130 190 240\n",
      " 170 130 190 160 130 150 180 180 190 190 180 230 150 150 200 230 170 190\n",
      " 140 150 150 220 160 190 180 180 160 170 180 150 160 150]\n"
     ]
    }
   ],
   "source": [
    "NewCases = np.genfromtxt('SPORK_rerun_new.csv', delimiter=',', usecols=(0,2,3,4,7,17),skip_header=1, dtype=int)\n",
    "NewCases1 = np.genfromtxt('SPORK_rerun_new.csv', delimiter=',', usecols=(0,2,3,4,7,17), dtype=str, skip_header=1)\n",
    "\n",
    "print(NewCases[0,:])\n",
    "print(NewCases1[0,:])\n",
    "\n",
    "ALL_sites = NewCases1[:,0]\n",
    "ALL_years = NewCases[:,1]\n",
    "ALL_months = NewCases[:,2]\n",
    "ALL_days = NewCases[:,3]\n",
    "ALL_hours = NewCases[:,4]\n",
    "ffds = NewCases[:,5]\n",
    "print(ffds)\n",
    "#ALL_TN = pickle.load(open('ALLVARTor_Non.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1fc7bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_stamp(ffd, ncfile, xoff, yoff, st_2a, st_2b):\n",
    "    ref = ncfile.variables['REFL'][:]\n",
    "    kdp = ncfile.variables['KDP'][:]\n",
    "    zdr = ncfile.variables['ZDR'][:]\n",
    "    cc = ncfile.variables['CC'][:]\n",
    "    zdr[ref < 20] = np.nan\n",
    "    zdr[cc < 0.9] = np.nan\n",
    "    kdp[ref < 20] = np.nan\n",
    "    kdp[cc < 0.9] = np.nan\n",
    "    nzdr = ncfile.variables['NZDR'][:]\n",
    "    nzdr[ref[:,4,:,:] < 20] = 0.0\n",
    "    nzdr[cc[:,4,:,:] < 0.95] = 0.0\n",
    "    zdrd = ncfile.variables['ZDRD'][:]\n",
    "    rot = ncfile.variables['ROT'][:]\n",
    "    times = ncfile.variables['Times'][:]\n",
    "    azim = ncfile.variables['azim'][:]\n",
    "    vel = ncfile.variables['VEL'][:]\n",
    "    \n",
    "    try:\n",
    "        ncfile7 = Dataset('D:/NewSPORK_stamps/SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(int(ALL_days[i]))+str(ALL_sites[i])+'.nc')\n",
    "        times = ncfile7.variables['Times'][:]\n",
    "\n",
    "    except:\n",
    "        ncfile7 = Dataset('D:/NewSPORK_stamps/SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(int(ALL_days[i])-1)+str(ALL_sites[i])+'.nc')\n",
    "        times = ncfile7.variables['Times'][:]\n",
    "\n",
    "    st_1 = datetime(int(ALL_years[i]), int(ALL_months[i]), int(ALL_days[i]), int(ALL_hours[i]), 0)-timedelta(minutes=30)\n",
    "    print(st_1)\n",
    "    time_diffs = []\n",
    "    for j in range(len(times)):\n",
    "\n",
    "        time_diff = (datetime.fromtimestamp(times[j]) - st_1).total_seconds()\n",
    "        time_diffs.append(time_diff)\n",
    "    time_array = np.asarray(time_diffs)  \n",
    "    time_array[time_array<0] = 9999\n",
    "    \n",
    "    #Set up logic to clip the time array to remove times when the storm is\n",
    "    #too far from the radar. Set the time_diffs at those times to be 9999.\n",
    "    #Removing times before the start time\n",
    "    if st_2a:\n",
    "        time_diffs2 = []\n",
    "        for j in range(len(times)):\n",
    "            time_diff2 = (datetime.fromtimestamp(times[j]) - st_2a).total_seconds()\n",
    "            time_diffs2.append(time_diff2)\n",
    "        time_array2 = np.asarray(time_diffs2)  \n",
    "        time_array[time_array2<0] = 9999\n",
    "        \n",
    "    #Removing times after the end time\n",
    "    if st_2b:\n",
    "        time_diffs3 = []\n",
    "        for j in range(len(times)):\n",
    "            time_diff3 = (datetime.fromtimestamp(times[j]) - st_2b).total_seconds()\n",
    "            time_diffs3.append(time_diff3)\n",
    "        time_array3 = np.asarray(time_diffs3)  \n",
    "        time_array[time_array3>0] = 9999\n",
    "    \n",
    "    print(time_array)\n",
    "    print(time_diffs)\n",
    "    print(np.where(time_array < 3600))\n",
    "    print(ref[time_array < 3600, :, :, :].shape[0], 'times')\n",
    "\n",
    "    ref_mn = ref[time_array < 3600, :, :, :]\n",
    "    zdr_mn = zdr[time_array < 3600, :, :, :]\n",
    "    kdp_mn = kdp[time_array < 3600, :, :, :]\n",
    "    cc_mn = cc[time_array < 3600, :, :, :]\n",
    "    rot_mn = rot[time_array < 3600, :, :, :]\n",
    "    zdrd_mn = zdrd[time_array < 3600, :, :]\n",
    "    nzdr_mn = nzdr[time_array < 3600, :, :]\n",
    "\n",
    "    ref_st = np.nanmean(ref_mn, axis=0)\n",
    "    zdr_st = np.nanmean(zdr_mn, axis=0)\n",
    "    kdp_st = np.nanmean(kdp_mn, axis=0)\n",
    "    cc_st = np.nanmean(cc_mn, axis=0)\n",
    "    rot_st = np.nanmean(rot_mn, axis=0)\n",
    "    zdrd_st = np.nanmean(zdrd_mn, axis=0)\n",
    "    nzdr_st = np.nanmean(nzdr_mn, axis=0)\n",
    "\n",
    "    nzdr_mn[np.isnan(nzdr_mn)] = 0.0\n",
    "    zdrd_mn[np.isnan(zdrd_mn)] = 0.0\n",
    "    zdr_mn[np.isnan(zdr_mn)] = 0.0\n",
    "    kdp_mn[np.isnan(kdp_mn)] = 0.0\n",
    "    cc_mn[np.isnan(cc_mn)] = 0.0\n",
    "    rot_mn[ref_mn < 20.0] = 0.0\n",
    "\n",
    "    ref_pm = _run_pmm_one_variable(ref_mn)\n",
    "    rot_pm = _run_pmm_one_variable(rot_mn)\n",
    "    zdrd_pm =  _run_pmm_one_variable(zdrd_mn)\n",
    "    nzdr_pm =  _run_pmm_one_variable(nzdr_mn)\n",
    "    zdr_pm =  _run_pmm_one_variable(zdr_mn)\n",
    "    kdp_pm =  _run_pmm_one_variable(kdp_mn)\n",
    "    cc_pm =  _run_pmm_one_variable(cc_mn)\n",
    "    for q in range(zdr_mn.shape[0]):\n",
    "        print(np.max(rot_mn[q,12,:,:]))\n",
    "    print(ref_mn.shape)\n",
    "    xr = np.arange(-70,70,1)\n",
    "    xra1, yra1 = DoRotation(xr, xr, RotRad=np.deg2rad((ffd)-180)*-1)\n",
    "    xri, yri, Z_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(ref_pm[4,:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, rot1_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(rot_pm[4,:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, rot3_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(rot_pm[12,:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, rot5_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(rot_pm[20,:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, rot7_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(rot_pm[28,:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, zdrd_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(zdrd_pm[:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, zdr_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(zdr_pm[4,:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, nzdr_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(nzdr_pm[:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, kdp_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(kdp_pm[4,:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, cc_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(cc_pm[4,:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    return xri, yri, Z_interpi, rot1_interpi, rot3_interpi, rot5_interpi, rot7_interpi, zdrd_interpi, nzdr_interpi, zdr_interpi, kdp_interpi, cc_interpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03be21b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of meso locations\n",
    "meso_locs = np.genfromtxt('MesocycloneLocationsPass3.csv', delimiter=',', skip_header=1)\n",
    "meso_x = meso_locs[206:,3]\n",
    "meso_y = meso_locs[206:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a3fcaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "print(len(meso_x))\n",
    "print(len(ALL_years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba3a68e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/SPORK_AC/SPORK_AC202254KAMA.nc\n",
      "2022-05-04 22:30:00\n",
      "[9999. 9999. 9999. 9999.  226.  472.  731.  977. 1245. 1621. 2030. 2425.\n",
      " 2792. 9999. 9999. 9999. 9999.]\n",
      "[-859.0, -577.0, -295.0, -36.0, 226.0, 472.0, 731.0, 977.0, 1245.0, 1621.0, 2030.0, 2425.0, 2792.0, 3159.0, 3555.0, 3965.0, 4363.0]\n",
      "(array([ 4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int64),)\n",
      "9 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matts\\AppData\\Local\\Temp\\ipykernel_34040\\2188689262.py:71: RuntimeWarning: Mean of empty slice\n",
      "  zdr_st = np.nanmean(zdr_mn, axis=0)\n",
      "C:\\Users\\matts\\AppData\\Local\\Temp\\ipykernel_34040\\2188689262.py:72: RuntimeWarning: Mean of empty slice\n",
      "  kdp_st = np.nanmean(kdp_mn, axis=0)\n",
      "C:\\Users\\matts\\AppData\\Local\\Temp\\ipykernel_34040\\2188689262.py:75: RuntimeWarning: Mean of empty slice\n",
      "  zdrd_st = np.nanmean(zdrd_mn, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008989215873783587\n",
      "0.009589099958929759\n",
      "0.009737348459797023\n",
      "0.007647672893665318\n",
      "0.007887307866553188\n",
      "0.007593793302889412\n",
      "0.01093955169285279\n",
      "0.004811864171043495\n",
      "0.006256046815425873\n",
      "(9, 41, 140, 140)\n"
     ]
    }
   ],
   "source": [
    "#Generate the file names for the postage stamps\n",
    "j=1\n",
    "#for i in range(len(ALL_years)):\n",
    "#for i in np.arange(1,104,1):\n",
    "for i in [68]:\n",
    "    try:\n",
    "        print('D:/SPORK_AC/SPORK_AC'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.nc')\n",
    "        ncfile = Dataset('D:/SPORK_AC/SPORK_AC'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.nc')\n",
    "    except:\n",
    "        try:\n",
    "            ncfile = Dataset('D:/SPORK_AC/SPORK_AC'+str(ALL_years[i])+str(ALL_months[i])+str(int(ALL_days[i])-1)+str(ALL_sites[i])+'.nc')\n",
    "        except:\n",
    "            print('SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.nc is missing!')\n",
    "            print(j)\n",
    "            j=j+1\n",
    "    try:\n",
    "        #rotated_data = rotate_stamp(ffds[i], ncfile, meso_x[i], meso_y[i])\n",
    "        rotated_data = rotate_stamp(ffds[i], ncfile, meso_x[i], meso_y[i], st_2a=None, st_2b=datetime(2022, 5, 4, 23, 22))\n",
    "\n",
    "        \n",
    "        with open('SPORK_SHIFT_AC3'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.pkl', 'wb') as f:\n",
    "            pickle.dump(rotated_data, f)\n",
    "    except:\n",
    "        print('SPORK_40_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.nc failed!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ef23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(24,24))\n",
    "xr2 = np.arange(0, len(rotated_data[0]), 1)\n",
    "reflevs = np.arange(20, 70, 5)\n",
    "zdrdlev = np.arange(1, 10, 1)\n",
    "rotlev = np.arange(0.002,0.01, 0.002)\n",
    "# plt.contourf(xr, xr, ref_st[4, :, :], reflevs, cmap=pyart.graph.cm_colorblind.HomeyerRainbow)\n",
    "# plt.contour(xr, xr, zdrd_st[:, :]/4, zdrdlev, cmap=plt.cm.viridis, linewidths=5)\n",
    "plt.contourf(rotated_data[0], rotated_data[1], rotated_data[2], reflevs, cmap=pyart.graph.cm_colorblind.HomeyerRainbow)\n",
    "plt.contourf(rotated_data[0], rotated_data[1], rotated_data[7]/4, zdrdlev, cmap=plt.cm.viridis)\n",
    "plt.contour(rotated_data[0], rotated_data[1], rotated_data[3], rotlev, colors='r', linewidths=4)\n",
    "plt.contour(rotated_data[0], rotated_data[1], rotated_data[4], rotlev, colors='purple', linewidths=4)\n",
    "plt.contour(rotated_data[0], rotated_data[1], rotated_data[5], rotlev, colors='blue', linewidths=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696428f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Geod\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#Create geod object for later distance and area calculations\n",
    "g = Geod(ellps='sphere')\n",
    "def radar_motion(start_time, end_time, sloni, slati, slone, slate):\n",
    "\n",
    "    stormdte = (np.datetime64(end_time) - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')\n",
    "    stormdtce = datetime.utcfromtimestamp(stormdte)\n",
    "    stormdti = (np.datetime64(start_time) - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')\n",
    "    stormdtci = datetime.utcfromtimestamp(stormdti)\n",
    "\n",
    "    distance_track = g.inv(sloni, slati,\n",
    "                           slone, slate)\n",
    "    dist_track = distance_track[2]                                        \n",
    "    if distance_track[1] < 0:\n",
    "        back = distance_track[1] + 360\n",
    "    else:\n",
    "        back = distance_track[1]\n",
    "    storm_dur = stormdtce-stormdtci\n",
    "    storm_sec = storm_dur.seconds\n",
    "    speed = dist_track/storm_sec\n",
    "    direc = back\n",
    "    return speed, direc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f53927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get observed motions for all of these cases\n",
    "#Generate the file names for the postage stamps\n",
    "j=1\n",
    "new_speeds = []\n",
    "new_directions = []\n",
    "\n",
    "for i in range(len(ALL_years)):\n",
    "#for i in np.arange(201,207,1):\n",
    "#for i in [104]:\n",
    "    try:\n",
    "        print('D:/NewSPORK_stamps/SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.nc')\n",
    "        ncfile = Dataset('D:/NewSPORK_stamps/SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.nc')\n",
    "    except:\n",
    "        try:\n",
    "            ncfile = Dataset('D:/NewSPORK_stamps/SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(int(ALL_days[i])-1)+str(ALL_sites[i])+'.nc')\n",
    "        except:\n",
    "            print('SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.nc is missing!')\n",
    "            print(j)\n",
    "            j=j+1\n",
    "    case_loni = ncfile.variables['Lons'][:,70,70] \n",
    "    case_lati = ncfile.variables['Lats'][:,70,70] \n",
    "    case_timesi = ncfile.variables['Times'][:] \n",
    "    #print(case_loni, case_lati, case_timesi)\n",
    "    \n",
    "    st_1 = datetime(int(ALL_years[i]), int(ALL_months[i]), int(ALL_days[i]), int(ALL_hours[i]), 0)-timedelta(minutes=30)\n",
    "    #print(st_1)\n",
    "    time_diffs = []\n",
    "    for j in range(len(case_timesi)):\n",
    "\n",
    "        time_diff = (datetime.fromtimestamp(case_timesi[j]) - st_1).total_seconds()\n",
    "        time_diffs.append(time_diff)\n",
    "    time_array = np.asarray(time_diffs)  \n",
    "    time_array[time_array<0] = 9999\n",
    "    #print(time_array)\n",
    "    #print(time_diffs)\n",
    "    #print(np.where(time_array < 3600))\n",
    "    \n",
    "    case_lon = case_loni[time_array < 3600]\n",
    "    case_lat = case_lati[time_array < 3600]\n",
    "    case_times = case_timesi[time_array < 3600]\n",
    "    \n",
    "    Xlon = np.array(case_lon)\n",
    "    Ylat = np.array(case_lat)\n",
    "    X_obs1 = Xlon[0]\n",
    "    X_obs2 = Xlon[-1]\n",
    "    X_mean = np.mean(Xlon)\n",
    "    Y_mean = np.mean(Ylat)\n",
    "    num = 0\n",
    "    den = 0\n",
    "    for i in range (len(Xlon)):\n",
    "        num += (Xlon[i] - X_mean)*(Ylat[i] - Y_mean)\n",
    "        den += (Xlon[i] - X_mean)**2\n",
    "    m = num / den\n",
    "    c = Y_mean - m*X_mean\n",
    "    Y_pred2 = m*X_obs2 + c\n",
    "    Y_pred1 = m*X_obs1 + c\n",
    "    #print(\"X_obs1, Y_pred1 =\", X_obs1, Y_pred1, \"; X_obs2, Y_pred2 =\", X_obs2, Y_pred2)\n",
    "    \n",
    "    st_speed, st_direction = radar_motion(datetime.fromtimestamp(case_times[0]), datetime.fromtimestamp(case_times[-1]), X_obs1, Y_pred1, X_obs2, Y_pred2)\n",
    "    \n",
    "    print(st_speed, st_direction)\n",
    "    \n",
    "    new_speeds.append(st_speed)\n",
    "    new_directions.append(st_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10a9d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ncfile.variables['Lons'][:,70,70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b366a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xlon)\n",
    "print(Xlon[0])\n",
    "print(Xlon[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f86413",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(case_times[0])\n",
    "timestamp = case_times[0]\n",
    "dt_object = datetime.fromtimestamp(timestamp)\n",
    "print(dt_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0698d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_speeds)\n",
    "print(new_directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770380c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "efilename = 'NewObsMotions.csv'\n",
    "with open(efilename, mode='w') as cal_file:\n",
    "    calWriter = csv.writer(cal_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "\n",
    "for i in range(len(ALL_years)):\n",
    "\n",
    "    with open(efilename, mode='a') as cal_file:\n",
    "            calWriter = csv.writer(cal_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "            calWriter.writerow([ALL_years[i], ALL_months[i], ALL_days[i], ALL_hours[i], new_speeds[i], new_directions[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d29c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
