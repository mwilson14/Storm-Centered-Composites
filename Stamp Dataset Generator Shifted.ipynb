{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c9b1b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\xarray\\core\\pycompat.py:22: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  duck_array_version = LooseVersion(duck_array_module.__version__)\n",
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\xarray\\core\\pycompat.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  duck_array_version = LooseVersion(\"0.0.0\")\n",
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\xarray\\core\\pycompat.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  duck_array_version = LooseVersion(\"0.0.0\")\n",
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\setuptools\\_distutils\\version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\setuptools\\_distutils\\version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\xarray\\core\\npcompat.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(np.__version__) >= \"1.20.0\":\n",
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\setuptools\\_distutils\\version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\xarray\\core\\pdcompat.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pd.__version__) < \"0.25.0\":\n",
      "C:\\Users\\matts\\anaconda3\\envs\\spork2022\\lib\\site-packages\\setuptools\\_distutils\\version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    }
   ],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy.ma as ma\n",
    "from cartopy.io.shapereader import Reader\n",
    "from cartopy.feature import ShapelyFeature\n",
    "import pyart\n",
    "import matplotlib.lines as mlines\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from metpy.interpolate.grid import natural_neighbor_to_grid\n",
    "from metpy.interpolate import interpolate_to_points\n",
    "from metpy.interpolate import interpolate_to_grid\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d09f425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2017 thunderhoser\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "import numpy\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "def _run_pmm_one_variable(\n",
    "        input_matrix, max_percentile_level=100):\n",
    "    \"\"\"Applies PMM to one variable.\n",
    "    E = number of examples (realizations over which to average)\n",
    "    :param input_matrix: numpy array.  The first axis must have length E.  Other\n",
    "        axes are assumed to be spatial dimensions.  Thus, input_matrix[i, ...]\n",
    "        is the spatial field for the [i]th example.\n",
    "    :param max_percentile_level: Maximum percentile.  No output value will\n",
    "        exceed the [q]th percentile of `input_matrix`, where q =\n",
    "        `max_percentile_level`.  Similarly, no output value will be less than\n",
    "        the [100 - q]th percentile of `input_matrix`.\n",
    "    :return: mean_field_matrix: numpy array of probability-matched means.  Will\n",
    "        have the same dimensions as `input_matrix`, except without the first\n",
    "        axis.  For example, if `input_matrix` is E x 32 x 32 x 12, this will be\n",
    "        32 x 32 x 12.\n",
    "    \"\"\"\n",
    "\n",
    "    # Pool values over all dimensions and remove extremes.\n",
    "    pooled_values = numpy.ravel(input_matrix)\n",
    "    pooled_values = numpy.sort(pooled_values)\n",
    "\n",
    "    max_pooled_value = numpy.percentile(pooled_values, max_percentile_level)\n",
    "    pooled_values = pooled_values[pooled_values <= max_pooled_value]\n",
    "\n",
    "    min_pooled_value = numpy.percentile(\n",
    "        pooled_values, 100 - max_percentile_level)\n",
    "    pooled_values = pooled_values[pooled_values >= min_pooled_value]\n",
    "\n",
    "    # Find ensemble mean at each grid point.\n",
    "    mean_field_matrix = numpy.mean(input_matrix, axis=0)\n",
    "    mean_field_flattened = numpy.ravel(mean_field_matrix)\n",
    "\n",
    "    # At each grid point, replace ensemble mean with the same percentile from\n",
    "    # pooled array.\n",
    "    pooled_value_percentiles = numpy.linspace(\n",
    "        0, 100, num=len(pooled_values), dtype=float)\n",
    "    mean_value_percentiles = numpy.linspace(\n",
    "        0, 100, num=len(mean_field_flattened), dtype=float)\n",
    "\n",
    "    sort_indices = numpy.argsort(mean_field_flattened)\n",
    "    unsort_indices = numpy.argsort(sort_indices)\n",
    "\n",
    "    interp_object = interp1d(\n",
    "        pooled_value_percentiles, pooled_values, kind='linear',\n",
    "        bounds_error=True, assume_sorted=True)\n",
    "\n",
    "    mean_field_flattened = interp_object(mean_value_percentiles)\n",
    "    mean_field_flattened = mean_field_flattened[unsort_indices]\n",
    "    mean_field_matrix = numpy.reshape(\n",
    "        mean_field_flattened, mean_field_matrix.shape)\n",
    "\n",
    "    return mean_field_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "158cb6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rotation code from https://stackoverflow.com/questions/29708840/rotate-meshgrid-with-numpy\n",
    "def DoRotation(xspan, yspan, RotRad=0):\n",
    "    \"\"\"Generate a meshgrid and rotate it by RotRad radians.\"\"\"\n",
    "\n",
    "    # Clockwise, 2D rotation matrix\n",
    "    RotMatrix = np.array([[np.cos(RotRad),  np.sin(RotRad)],\n",
    "                          [-np.sin(RotRad), np.cos(RotRad)]])\n",
    "\n",
    "    x, y = np.meshgrid(xspan, yspan)\n",
    "    return np.einsum('ji, mni -> jmn', RotMatrix, np.dstack([x, y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "786c8d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leg1_PDD = Dataset('D:/P3_Syntheses/PDDkd_synthesis_2019_06_08_204430.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cefb7e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the sounding data from the spreadsheet\n",
    "#Bring in the sounding data\n",
    "CIsoundings=np.genfromtxt('SupercellSoundings/environment_cicases_Final.csv',skip_header=1,delimiter=',', dtype=str)\n",
    "Oldsoundings=np.genfromtxt('SupercellSoundings/environment_Oldcases.csv',delimiter=',', dtype=str)\n",
    "# ETsoundings=np.genfromtxt('PythonEnvVars1.csv', skip_header=1,delimiter=',')\n",
    "# ETsoundings[ETsoundings==-9999]=np.nan\n",
    "\n",
    "NewSoundings=np.genfromtxt('SupercellSoundingsNew/environment_cicases1022.csv', delimiter=',', dtype=str)\n",
    "\n",
    "TORsondes = pickle.load(open('TORsondes.pkl', 'rb'))\n",
    "NTORsondes = pickle.load(open('NTORsondes.pkl', 'rb'))\n",
    "ETORsondes = pickle.load(open('ETORsondes.pkl', 'rb'))\n",
    "ENTORsondes = pickle.load(open('ENTORsondes.pkl', 'rb'))\n",
    "TTorsondes = pickle.load(open('TTorsondes.pkl', 'rb'))\n",
    "TNTsondes = pickle.load(open('TNTsondes.pkl', 'rb'))\n",
    "STsondes = pickle.load(open('STsondes.pkl', 'rb'))\n",
    "SNsondes = pickle.load(open('SNsondes.pkl', 'rb'))\n",
    "\n",
    "ALL_sites = pickle.load(open('ALLVARSite.pkl', 'rb'))\n",
    "ALL_years = pickle.load(open('ALLVARYear.pkl', 'rb'))\n",
    "ALL_months = pickle.load(open('ALLVARMonth.pkl', 'rb'))\n",
    "ALL_days = pickle.load(open('ALLVARDay.pkl', 'rb'))\n",
    "ALL_hours = pickle.load(open('ALLVARHour.pkl', 'rb'))\n",
    "ALL_TN = pickle.load(open('ALLVARTor_Non.pkl', 'rb'))\n",
    "\n",
    "ALL_b_t = np.zeros((ALL_TN.shape))\n",
    "ALL_b_t[ALL_TN=='T'] = 1.0\n",
    "\n",
    "#Fix the incorrect entry here\n",
    "ALL_sites[44] = 'KTLX'\n",
    "ALL_years[44] = 2019\n",
    "ALL_months[44] = 3\n",
    "ALL_days[44] = 23\n",
    "ALL_hours[44] = 23\n",
    "ALL_TN[44] = 'N'\n",
    "\n",
    "#Fix second incorrect entry here\n",
    "ALL_sites[54] = 'KFDR'\n",
    "ALL_years[54] = 2013\n",
    "ALL_months[54] = 4\n",
    "ALL_days[54] = 18\n",
    "ALL_hours[54] = 1\n",
    "ALL_TN[54] = 'T'\n",
    "\n",
    "#Fix third incorrect entry here\n",
    "ALL_sites[61] = 'KENX'\n",
    "ALL_years[61] = 2014\n",
    "ALL_months[61] = 7\n",
    "ALL_days[61] = 3\n",
    "ALL_hours[61] = 21\n",
    "ALL_TN[61] = 'N'\n",
    "\n",
    "#Fix fourth incorrect entry here\n",
    "ALL_sites[137] = 'KLZK'\n",
    "ALL_years[137] = 2014\n",
    "ALL_months[137] = 4\n",
    "ALL_days[137] = 28\n",
    "ALL_hours[137] = 1\n",
    "ALL_TN[137] = 'T'\n",
    "\n",
    "obsd_TOR = pickle.load(open('sp6_dir_TOR.pkl', 'rb'))\n",
    "obsd_NTOR = pickle.load(open('sp6_dir_NTOR.pkl', 'rb'))\n",
    "obsd_ETOR = pickle.load(open('sp6_dir_ETOR.pkl', 'rb'))\n",
    "obsd_ENTOR = pickle.load(open('sp6_dir_ENTOR.pkl', 'rb'))\n",
    "obsd_TTor = pickle.load(open('sp6_dir_TTor.pkl', 'rb'))\n",
    "obsd_TNT = pickle.load(open('sp6_dir_TNT.pkl', 'rb'))\n",
    "obsd_ST = pickle.load(open('sp6_dir_ST.pkl', 'rb'))\n",
    "obsd_SN = pickle.load(open('sp6_dir_SN.pkl', 'rb'))\n",
    "\n",
    "obspd_TOR = pickle.load(open('sp6_sp_TOR.pkl', 'rb'))\n",
    "obspd_NTOR = pickle.load(open('sp6_sp_NTOR.pkl', 'rb'))\n",
    "obspd_ETOR = pickle.load(open('sp6_sp_ETOR.pkl', 'rb'))\n",
    "obspd_ENTOR = pickle.load(open('sp6_sp_ENTOR.pkl', 'rb'))\n",
    "obspd_TTor = pickle.load(open('sp6_sp_TTor.pkl', 'rb'))\n",
    "obspd_TNT = pickle.load(open('sp6_sp_TNT.pkl', 'rb'))\n",
    "obspd_ST = pickle.load(open('sp6_sp_ST.pkl', 'rb'))\n",
    "obspd_SN = pickle.load(open('sp6_sp_SN.pkl', 'rb'))\n",
    "\n",
    "#Create the full arrays for storm speed and direction\n",
    "all_dir = np.concatenate([obsd_TOR, obsd_NTOR, obsd_ETOR, obsd_ENTOR, obsd_TTor, obsd_TNT, obsd_ST, obsd_SN], axis=0)\n",
    "all_spd = np.concatenate([obspd_TOR, obspd_NTOR, obspd_ETOR, obspd_ENTOR, obspd_TTor, obspd_TNT, obspd_ST, obspd_SN], axis=0)\n",
    "\n",
    "#Get FFD angle dataset\n",
    "ffdA = 190\n",
    "ffdBB = 190\n",
    "ffdCC = 190\n",
    "ffdEE = 200\n",
    "ffdFF = 230\n",
    "ffdH = 150\n",
    "ffdHH = 210\n",
    "ffdI = 160\n",
    "ffdJ = 170\n",
    "ffdK = 120\n",
    "ffdR = 200\n",
    "ffdS = 160\n",
    "ffdGG = 180\n",
    "ffdE = 230\n",
    "\n",
    "ffd1 = 140\n",
    "ffd3 = 220\n",
    "ffd6 = 190\n",
    "ffd15 = 170\n",
    "ffd22 = 130\n",
    "ffd10 = 170\n",
    "ffd13 = 150\n",
    "ffd14 = 160\n",
    "ffd16 = 180\n",
    "ffd19 = 200\n",
    "ffd21 = 150\n",
    "ffd23 = 180\n",
    "ffd24 = 190\n",
    "ffd26 = 200\n",
    "ffd27 = 160\n",
    "ffd28 = 180\n",
    "ffd29 = 180\n",
    "ffd30 = 210\n",
    "ffd32 = 160\n",
    "\n",
    "ffdet1 = 180\n",
    "ffdet3 = 165\n",
    "ffdet6 = 125\n",
    "ffdet8 = 170\n",
    "ffdet9 = 205\n",
    "ffdet11 = 190\n",
    "ffdet13 = 180\n",
    "ffdet14 = 220\n",
    "ffdet16 = 145\n",
    "ffdet20 = 190\n",
    "ffdet23 = 195\n",
    "ffdet26 = 170\n",
    "ffdet33 = 110\n",
    "ffdet34 = 150\n",
    "ffdet35 = 180\n",
    "ffdet36 = 140\n",
    "\n",
    "ffden1 = 130\n",
    "ffden2 = 165\n",
    "ffden4 = 140\n",
    "ffden7 = 180\n",
    "ffden8 = 180\n",
    "ffden9 = 150\n",
    "ffden10 = 170\n",
    "ffden11 = 125\n",
    "ffden12 = 170\n",
    "\n",
    "ffdcit1 = 225\n",
    "ffdcit2 = 180\n",
    "ffdcit3 = 190\n",
    "ffdcit4 = 225\n",
    "ffdcit5 = 155\n",
    "ffdcit6 = 190\n",
    "ffdcit8 = 200\n",
    "ffdcit9 = 170\n",
    "ffdcit10 = 190\n",
    "ffdcit11 = 165\n",
    "ffdcit12 = 190\n",
    "ffdcit13 = 150\n",
    "ffdcit14 = 180\n",
    "ffdcit15 = 140\n",
    "ffdcit17 = 190\n",
    "ffdcit18 = 260\n",
    "ffdcit19 = 190\n",
    "ffdcit20 = 165\n",
    "ffdcit22 = 190\n",
    "ffdcit23 = 185\n",
    "ffdcit24 = 130\n",
    "ffdcit26 = 120\n",
    "ffdcit27 = 130\n",
    "ffdcit28 = 165\n",
    "ffdcit29 = 170\n",
    "ffdcit30 = 155\n",
    "ffdcit31 = 145\n",
    "ffdcit32 = 200\n",
    "ffdcit34 = 170\n",
    "\n",
    "ffdcin1 = 190\n",
    "ffdcin2 = 180\n",
    "ffdcin3 = 190\n",
    "ffdcin4 = 180\n",
    "ffdcin5 = 150\n",
    "ffdcin6 = 210\n",
    "ffdcin9 = 200\n",
    "ffdcin10 = 160\n",
    "ffdcin11 = 185\n",
    "ffdcin12 = 140\n",
    "ffdcin13 = 170\n",
    "ffdcin14 = 195\n",
    "ffdcin15 = 185\n",
    "ffdcin16 = 150\n",
    "ffdcin17 = 165\n",
    "ffdcin18 = 165\n",
    "\n",
    "ffdSN1 = 195\n",
    "ffdSN2 = 160\n",
    "ffdSN3 = 160 \n",
    "ffdSN4 = 175\n",
    "ffdSN5 = 170\n",
    "ffdSN6 = 180\n",
    "ffdSN7 = 145\n",
    "ffdSN8 = 205\n",
    "ffdSN9 = 200\n",
    "ffdSN10 = 220\n",
    "ffdSN11 = 180\n",
    "ffdSN12 = 175\n",
    "ffdSN13 = 135\n",
    "ffdSN14 = 200\n",
    "ffdSN15 = 235\n",
    "ffdSN16 = 180\n",
    "ffdSN17 = 180\n",
    "ffdSN18 = 175\n",
    "ffdSN19 = 225\n",
    "ffdSN20 = 155\n",
    "ffdSN21 = 150\n",
    "ffdSN22 = 180\n",
    "ffdSN23 = 185\n",
    "ffdSN24 = 180\n",
    "ffdSN25 = 190\n",
    "ffdSN26 = 160\n",
    "ffdSN27 = 160\n",
    "ffdSN28 = 240\n",
    "ffdSN29 = 180\n",
    "ffdSN30 = 245\n",
    "ffdSN31 = 125\n",
    "ffdSN32 = 130\n",
    "ffdSN33 = 210\n",
    "ffdSN34 = 175\n",
    "ffdSN35 = 165\n",
    "ffdSN36 = 140\n",
    "ffdSN37 = 170\n",
    "ffdSN38 = 175\n",
    "ffdSN39 = 180\n",
    "ffdSN40 = 210\n",
    "ffdSN42 = 195\n",
    "ffdSN43 = 170\n",
    "ffdSN44 = 180\n",
    "ffdSN45 = 210\n",
    "ffdSN46 = 225\n",
    "ffdSN47 = 150\n",
    "ffdSN48 = 230\n",
    "ffdSN49 = 200\n",
    "ffdSN50 = 190\n",
    "\n",
    "ffdSN51 = 190\n",
    "ffdSN52 = 220\n",
    "ffdSN53 = 220\n",
    "ffdSN54 = 215\n",
    "ffdSN55 = 170\n",
    "\n",
    "ffdSN56 = 195\n",
    "ffdSN57 = 180\n",
    "ffdSN58 = 155\n",
    "ffdSN59 = 185\n",
    "ffdSN60 = 190\n",
    "\n",
    "\n",
    "ffdST1 = 115\n",
    "ffdST2 = 150\n",
    "ffdST3 = 150\n",
    "ffdST4 = 175\n",
    "ffdST5 = 200\n",
    "ffdST6 = 115\n",
    "ffdST7 = 160\n",
    "ffdST8 = 120\n",
    "ffdST9 = 180\n",
    "ffdST10 = 155\n",
    "ffdST11 = 160\n",
    "ffdST12 = 180\n",
    "ffdST13 = 225\n",
    "ffdST14 = 210\n",
    "ffdST15 = 180\n",
    "ffdST16 = 155\n",
    "ffdST17 = 180\n",
    "ffdST18 = 185\n",
    "ffdST19 = 170\n",
    "ffdST20 = 135\n",
    "ffdST21 = 185\n",
    "ffdST24 = 160\n",
    "ffdST27 = 180\n",
    "ffdST28 = 165\n",
    "ffdST30 = 245\n",
    "ffdST31 = 155\n",
    "ffdST33 = 180\n",
    "ffdST34 = 140\n",
    "ffdST35 = 140\n",
    "ffdST37 = 185\n",
    "ffdST38 = 210\n",
    "ffdST39 = 155\n",
    "ffdST40 = 205\n",
    "ffdST41 = 140\n",
    "ffdST42 = 150\n",
    "ffdST43 = 160\n",
    "ffdST44 = 200\n",
    "ffdST45 = 185\n",
    "ffdST47 = 195\n",
    "ffdST48 = 190\n",
    "ffdST50 = 185\n",
    "ffdST51 = 170\n",
    "ffdST52 = 205\n",
    "ffdST53 = 240\n",
    "\n",
    "ffds = np.asarray([ffdcit1, ffdcit2, ffdcit3, ffdcit4, ffdcit5, ffdcit6, ffdcit8, ffdcit9, ffdcit10,\n",
    "        ffdcit11, ffdcit12, ffdcit13, ffdcit14, ffdcit15, ffdcit17, ffdcit18, ffdcit19, ffdcit20, ffdcit22, ffdcit23,\n",
    "        ffdcit24, ffdcit26, ffdcit27, ffdcit28, ffdcit29, ffdcit30, ffdcit31, ffdcit32, ffdcit34, ffdcin1, ffdcin2,\n",
    "        ffdcin3, ffdcin4, ffdcin5, ffdcin6, ffdcin9, ffdcin10, ffdcin11, ffdcin12, ffdcin13, ffdcin14, ffdcin15, ffdcin16,\n",
    "        ffdcin17, ffdcin18,ffdet1, ffdet3, ffdet6, ffdet8, ffdet9, ffdet11, ffdet13, ffdet14, ffdet16, ffdet20,\n",
    "        ffdet23, ffdet26, ffdet33, ffdet34, ffdet35, ffdet36, ffden1, ffden2, ffden4, ffden7, ffden8, ffden9, \n",
    "        ffden10, ffden11, ffden12,ffdA, ffdBB, ffdCC, ffdEE, ffdFF, ffdH, ffdHH, ffdI, ffdJ, ffdK, ffdR, ffdS, ffdGG, ffdE, ffd1, ffd3, ffd6,\n",
    "        ffd15, ffd22, ffd10, ffd13, ffd14, ffd16, ffd19, ffd21, ffd23, ffd24, ffd26, ffd27, ffd28, ffd29, \n",
    "        ffd30, ffd32,ffdST1, ffdST2, ffdST3, ffdST4, ffdST5, ffdST6, ffdST7, ffdST8, ffdST9, ffdST10, ffdST11,\n",
    "        ffdST12, ffdST13, ffdST14, ffdST15, ffdST16, ffdST17, ffdST18, ffdST19, ffdST20, ffdST21, ffdST24, ffdST27, \n",
    "        ffdST28, ffdST30, ffdST31, ffdST33, ffdST34, ffdST35, ffdST37, ffdST38, ffdST39, ffdST40, ffdST41, ffdST42,\n",
    "        ffdST43, ffdST44, ffdST45, ffdST47, ffdST48, ffdST50, ffdST51, ffdST52, ffdST53,ffdSN1,\n",
    "        ffdSN2,ffdSN3,ffdSN4,ffdSN5,ffdSN6,ffdSN7,ffdSN8,ffdSN9,ffdSN10,ffdSN11,ffdSN12,ffdSN13,ffdSN14,ffdSN15,ffdSN16,ffdSN17,\n",
    "        ffdSN18,ffdSN19,ffdSN20,ffdSN21,ffdSN22,ffdSN23,ffdSN24,ffdSN25,ffdSN26,ffdSN27,ffdSN28,ffdSN29,ffdSN30,ffdSN31,ffdSN32,ffdSN33,\n",
    "        ffdSN34,ffdSN35,ffdSN36,ffdSN37,ffdSN38,ffdSN39,ffdSN40,ffdSN42,ffdSN43,ffdSN44,ffdSN45,ffdSN46,ffdSN47,ffdSN48,ffdSN49,ffdSN50,\n",
    "        ffdSN51,ffdSN52,ffdSN53,ffdSN54,ffdSN55,ffdSN56,ffdSN57,ffdSN58,ffdSN59,ffdSN60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a4a163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_stamp(ffd, ncfile, xoff, yoff, st_2a, st_2b):\n",
    "    ref = ncfile.variables['REFL'][:]\n",
    "    kdp = ncfile.variables['KDP'][:]\n",
    "    zdr = ncfile.variables['ZDR'][:]\n",
    "    cc = ncfile.variables['CC'][:]\n",
    "    zdr[ref < 20] = np.nan\n",
    "    zdr[cc < 0.9] = np.nan\n",
    "    kdp[ref < 20] = np.nan\n",
    "    kdp[cc < 0.9] = np.nan\n",
    "    nzdr = ncfile.variables['NZDR'][:]\n",
    "    nzdr[ref[:,4,:,:] < 20] = 0.0\n",
    "    nzdr[cc[:,4,:,:] < 0.95] = 0.0\n",
    "    zdrd = ncfile.variables['ZDRD'][:]\n",
    "    rot = ncfile.variables['ROT'][:]\n",
    "    times = ncfile.variables['Times'][:]\n",
    "    azim = ncfile.variables['azim'][:]\n",
    "    vel = ncfile.variables['VEL'][:]\n",
    "    \n",
    "    try:\n",
    "        ncfile7 = Dataset('D:/NewSPORK_stamps/SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(int(ALL_days[i]))+str(ALL_sites[i])+'.nc')\n",
    "        times = ncfile7.variables['Times'][:]\n",
    "\n",
    "    except:\n",
    "        ncfile7 = Dataset('D:/NewSPORK_stamps/SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(int(ALL_days[i])-1)+str(ALL_sites[i])+'.nc')\n",
    "        times = ncfile7.variables['Times'][:]\n",
    "\n",
    "    st_1 = datetime(int(ALL_years[i]), int(ALL_months[i]), int(ALL_days[i]), int(ALL_hours[i]), 0)-timedelta(minutes=30)\n",
    "    print(st_1)\n",
    "    time_diffs = []\n",
    "    for j in range(len(times)):\n",
    "\n",
    "        time_diff = (datetime.fromtimestamp(times[j]) - st_1).total_seconds()\n",
    "        time_diffs.append(time_diff)\n",
    "    time_array = np.asarray(time_diffs)  \n",
    "    time_array[time_array<0] = 9999\n",
    "    \n",
    "    #Set up logic to clip the time array to remove times when the storm is\n",
    "    #too far from the radar. Set the time_diffs at those times to be 9999.\n",
    "    #Removing times before the start time\n",
    "    if st_2a:\n",
    "        time_diffs2 = []\n",
    "        for j in range(len(times)):\n",
    "            time_diff2 = (datetime.fromtimestamp(times[j]) - st_2a).total_seconds()\n",
    "            time_diffs2.append(time_diff2)\n",
    "        time_array2 = np.asarray(time_diffs2)  \n",
    "        time_array[time_array2<0] = 9999\n",
    "        \n",
    "    #Removing times after the end time\n",
    "    if st_2b:\n",
    "        time_diffs3 = []\n",
    "        for j in range(len(times)):\n",
    "            time_diff3 = (datetime.fromtimestamp(times[j]) - st_2b).total_seconds()\n",
    "            time_diffs3.append(time_diff3)\n",
    "        time_array3 = np.asarray(time_diffs3)  \n",
    "        time_array[time_array3>0] = 9999\n",
    "    \n",
    "    print(time_array)\n",
    "    print(time_diffs)\n",
    "    print(np.where(time_array < 3600))\n",
    "    print(ref[time_array < 3600, :, :, :].shape[0], 'times')\n",
    "\n",
    "    ref_mn = ref[time_array < 3600, :, :, :]\n",
    "    zdr_mn = zdr[time_array < 3600, :, :, :]\n",
    "    kdp_mn = kdp[time_array < 3600, :, :, :]\n",
    "    cc_mn = cc[time_array < 3600, :, :, :]\n",
    "    rot_mn = rot[time_array < 3600, :, :, :]\n",
    "    zdrd_mn = zdrd[time_array < 3600, :, :]\n",
    "    nzdr_mn = nzdr[time_array < 3600, :, :]\n",
    "\n",
    "    ref_st = np.nanmean(ref_mn, axis=0)\n",
    "    zdr_st = np.nanmean(zdr_mn, axis=0)\n",
    "    kdp_st = np.nanmean(kdp_mn, axis=0)\n",
    "    cc_st = np.nanmean(cc_mn, axis=0)\n",
    "    rot_st = np.nanmean(rot_mn, axis=0)\n",
    "    zdrd_st = np.nanmean(zdrd_mn, axis=0)\n",
    "    nzdr_st = np.nanmean(nzdr_mn, axis=0)\n",
    "\n",
    "    nzdr_mn[np.isnan(nzdr_mn)] = 0.0\n",
    "    zdrd_mn[np.isnan(zdrd_mn)] = 0.0\n",
    "    zdr_mn[np.isnan(zdr_mn)] = 0.0\n",
    "    kdp_mn[np.isnan(kdp_mn)] = 0.0\n",
    "    cc_mn[np.isnan(cc_mn)] = 0.0\n",
    "    rot_mn[ref_mn < 20.0] = 0.0\n",
    "\n",
    "    ref_pm = _run_pmm_one_variable(ref_mn)\n",
    "    rot_pm = _run_pmm_one_variable(rot_mn)\n",
    "    zdrd_pm =  _run_pmm_one_variable(zdrd_mn)\n",
    "    nzdr_pm =  _run_pmm_one_variable(nzdr_mn)\n",
    "    zdr_pm =  _run_pmm_one_variable(zdr_mn)\n",
    "    kdp_pm =  _run_pmm_one_variable(kdp_mn)\n",
    "    cc_pm =  _run_pmm_one_variable(cc_mn)\n",
    "    for q in range(zdr_mn.shape[0]):\n",
    "        print(np.max(rot_mn[q,12,:,:]))\n",
    "    print(ref_mn.shape)\n",
    "    xr = np.arange(-70,70,1)\n",
    "    xra1, yra1 = DoRotation(xr, xr, RotRad=np.deg2rad((ffd)-180)*-1)\n",
    "    xri, yri, Z_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(ref_pm[4,:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, rot1_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(rot_pm[4,:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, rot3_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(rot_pm[12,:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, rot5_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(rot_pm[20,:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, rot7_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(rot_pm[28,:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, zdrd_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(zdrd_pm[:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, zdr_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(zdr_pm[4,:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, nzdr_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(nzdr_pm[:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, kdp_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(kdp_pm[4,:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    xri, yri, cc_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                             np.ndarray.flatten(cc_pm[4,:,:]), hres=1,\n",
    "                                             boundary_coords={'west':-50+xoff,'south':-50+yoff,'east':49+xoff,'north':49+yoff})\n",
    "    return xri, yri, Z_interpi, rot1_interpi, rot3_interpi, rot5_interpi, rot7_interpi, zdrd_interpi, nzdr_interpi, zdr_interpi, kdp_interpi, cc_interpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87b379a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of meso locations\n",
    "meso_locs = np.genfromtxt('MesocycloneLocationsPass3.csv', delimiter=',', skip_header=1)\n",
    "meso_x = meso_locs[:,3]\n",
    "meso_y = meso_locs[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab642567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(meso_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea296cde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/SPORK_AC/SPORK_AC2020526KDFX.nc\n",
      "2020-05-26 00:30:00\n",
      "[9999. 9999. 1017. 1375. 1716. 2073. 2414. 2755. 3096. 3475. 3852.]\n",
      "[311.0, 668.0, 1017.0, 1375.0, 1716.0, 2073.0, 2414.0, 2755.0, 3096.0, 3475.0, 3852.0]\n",
      "(array([2, 3, 4, 5, 6, 7, 8, 9], dtype=int64),)\n",
      "8 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matts\\AppData\\Local\\Temp\\ipykernel_30940\\2188689262.py:71: RuntimeWarning: Mean of empty slice\n",
      "  zdr_st = np.nanmean(zdr_mn, axis=0)\n",
      "C:\\Users\\matts\\AppData\\Local\\Temp\\ipykernel_30940\\2188689262.py:72: RuntimeWarning: Mean of empty slice\n",
      "  kdp_st = np.nanmean(kdp_mn, axis=0)\n",
      "C:\\Users\\matts\\AppData\\Local\\Temp\\ipykernel_30940\\2188689262.py:75: RuntimeWarning: Mean of empty slice\n",
      "  zdrd_st = np.nanmean(zdrd_mn, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004603962805955598\n",
      "0.00424872932794557\n",
      "0.003233167235348606\n",
      "0.004588565727791287\n",
      "0.004010639608992599\n",
      "0.0038408883271229266\n",
      "0.008208522947574662\n",
      "0.004741849734697935\n",
      "(8, 41, 140, 140)\n"
     ]
    }
   ],
   "source": [
    "#Generate the file names for the postage stamps\n",
    "j=1\n",
    "#for i in range(len(ALL_years)):\n",
    "#for i in np.arange(126,205,1):\n",
    "#for i in np.arange(1,206,1):\n",
    "\n",
    "for i in [203]:\n",
    "    try:\n",
    "        print('D:/SPORK_AC/SPORK_AC'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.nc')\n",
    "        ncfile = Dataset('D:/SPORK_AC/SPORK_AC'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.nc')\n",
    "    except:\n",
    "        try:\n",
    "            ncfile = Dataset('D:/SPORK_AC/SPORK_AC'+str(ALL_years[i])+str(ALL_months[i])+str(int(ALL_days[i])-1)+str(ALL_sites[i])+'.nc')\n",
    "        except:\n",
    "            print('SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.nc is missing!')\n",
    "            print(j)\n",
    "            j=j+1\n",
    "    #try:\n",
    "    #rotated_data = rotate_stamp(ffds[i], ncfile, -9, -14)\n",
    "    rotated_data = rotate_stamp(ffds[i], ncfile, meso_x[i], meso_y[i], st_2a=datetime(2020,5,26,0,45), st_2b=None)\n",
    "    \n",
    "    with open('SPORK_SHIFT_AC3'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.pkl', 'wb') as f:\n",
    "        pickle.dump(rotated_data, f)\n",
    "#     except:\n",
    "#         print('SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.nc failed!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a436beaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409,)\n"
     ]
    }
   ],
   "source": [
    "print(meso_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fe2c54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPORK_RERUN201727KDGX 0\n",
      "SPORK_RERUN201742KPOE 1\n",
      "SPORK_RERUN2014618KFSD 2\n",
      "SPORK_RERUN2015714KIND 3\n",
      "SPORK_RERUN2016331KINX 4\n",
      "SPORK_RERUN2016524KDDC 5\n",
      "SPORK_RERUN2016827KMVX 6\n",
      "SPORK_RERUN2017518KFDR 7\n",
      "SPORK_RERUN2017712KMVX 8\n",
      "SPORK_RERUN2018529KDDC 9\n",
      "SPORK_RERUN2018611KOAX 10\n",
      "SPORK_RERUN20151117KAMA 11\n",
      "SPORK_RERUN201556KVNX 12\n",
      "SPORK_RERUN201559KFDR 13\n",
      "SPORK_RERUN2015623KDVN 14\n",
      "SPORK_RERUN2015627KMVX 15\n",
      "SPORK_RERUN2016510KPAH 16\n",
      "SPORK_RERUN20161129KDGX 17\n",
      "SPORK_RERUN201641KGWX 18\n",
      "SPORK_RERUN20161130KGWX 19\n",
      "SPORK_RERUN20151225KBMX 20\n",
      "SPORK_RERUN201659KOAX 21\n",
      "SPORK_RERUN2017328KLBB 22\n",
      "SPORK_RERUN2015516KFDR 23\n",
      "SPORK_RERUN2016316KILX 24\n",
      "SPORK_RERUN2017228KDVN 25\n",
      "SPORK_RERUN2018121KILX 26\n",
      "SPORK_RERUN201933KMXX 27\n",
      "SPORK_RERUN2019315KBMX 28\n",
      "SPORK_RERUN201851KDDC 29\n",
      "SPORK_RERUN201851KUEX 30\n",
      "SPORK_RERUN201873KLNX 31\n",
      "SPORK_RERUN2016718KUDX 32\n",
      "SPORK_RERUN201558KLBB 33\n",
      "SPORK_RERUN2015713KDVN 34\n",
      "SPORK_RERUN2015527KAMA 35\n",
      "SPORK_RERUN2016121KDGX 36\n",
      "SPORK_RERUN2018514KSJT 37\n",
      "SPORK_RERUN2015918KUEX 38\n",
      "SPORK_RERUN201619KHGX 39\n",
      "SPORK_RERUN2014810KUEX 40\n",
      "SPORK_RERUN2016524KUEX 41\n",
      "SPORK_RERUN2016410KLBB 42\n",
      "SPORK_RERUN2016411KFDR 43\n",
      "SPORK_RERUN2019323KTLX 44\n",
      "SPORK_RERUN201232KOHX 45\n",
      "SPORK_RERUN201362KGSP 46\n",
      "SPORK_RERUN201371KLWX 47\n",
      "SPORK_RERUN201379KBIS 48\n",
      "SPORK_RERUN201387KCLE 49\n",
      "SPORK_RERUN2012229KICT 50\n",
      "SPORK_RERUN2012415KDDC 51\n",
      "SPORK_RERUN2012531KSJT 52\n",
      "SPORK_RERUN2013129KSRX 53\n",
      "SPORK_RERUN2013418KFDR 54\n",
      "SPORK_RERUN2013520KTLX 55\n",
      "SPORK_RERUN2013612KLOT 56\n",
      "SPORK_RERUN2013818KFFC 57\n",
      "SPORK_RERUN20131117KILX 58\n",
      "SPORK_RERUN20131117KPAH 59\n",
      "SPORK_RERUN20131221KLZK 60\n",
      "SPORK_RERUN201473KENX 61\n",
      "SPORK_RERUN201477KBOX 62\n",
      "SPORK_RERUN2012429KAMA 63\n",
      "SPORK_RERUN2013510KEWX 64\n",
      "SPORK_RERUN2013617KGRB 65\n",
      "SPORK_RERUN2013810KAKQ 66\n",
      "SPORK_RERUN2014315KDYX 67\n",
      "SPORK_RERUN2014429KGRR 68\n",
      "SPORK_RERUN2014521KGLD 69\n",
      "SPORK_RERUN2013831KBIS 70\n",
      "SPORK_RERUN2013520KINX 71\n",
      "SPORK_RERUN2013619KLBB 72\n",
      "SPORK_RERUN201269KMQT 73\n",
      "SPORK_RERUN2012427KOHX 74\n",
      "SPORK_RERUN2013520KEAX 75\n",
      "SPORK_RERUN2013331KSRX 76\n",
      "SPORK_RERUN2013318KFFC 77\n",
      "SPORK_RERUN2012430KDDC 78\n",
      "SPORK_RERUN2012510KEWX 79\n",
      "SPORK_RERUN2013516KFWS 80\n",
      "SPORK_RERUN20131117KIND 81\n",
      "SPORK_RERUN2013618KRAX 82\n",
      "SPORK_RERUN2013828KDTX 83\n",
      "SPORK_RERUN2013427KFDR 84\n",
      "SPORK_RERUN2013530KFDR 85\n",
      "SPORK_RERUN2013423KVNX 86\n",
      "SPORK_RERUN2013813KDIX 87\n",
      "SPORK_RERUN201375KJKL 88\n",
      "SPORK_RERUN201494KBIS 89\n",
      "SPORK_RERUN20131014KDDC 90\n",
      "SPORK_RERUN2013318KDGX 91\n",
      "SPORK_RERUN2013617KDTX 92\n",
      "SPORK_RERUN20131027KFWS 93\n",
      "SPORK_RERUN201443KICT 94\n",
      "SPORK_RERUN2014521KLOT 95\n",
      "SPORK_RERUN201386KMPX 96\n",
      "SPORK_RERUN201348KSGF 97\n",
      "SPORK_RERUN2013710KABR 98\n",
      "SPORK_RERUN2013521KDMX 99\n",
      "SPORK_RERUN2013525KUDX 100\n",
      "SPORK_RERUN2013723KUDX 101\n",
      "SPORK_RERUN2014520KFTG 102\n",
      "SPORK_RERUN2014521KFTG 103\n",
      "SPORK_RERUN20161127KUEX 104\n",
      "SPORK_RERUN2017121KSHV 105\n",
      "SPORK_RERUN2017122KPOE 106\n",
      "SPORK_RERUN2018514KICT 107\n",
      "SPORK_RERUN2018531KSFX 108\n",
      "SPORK_RERUN2019413KGRK 109\n",
      "SPORK_RERUN2019414KILN 110\n",
      "SPORK_RERUN2019430KINX 111\n",
      "SPORK_RERUN201951KSGF 112\n",
      "SPORK_RERUN2019430KFDR 113\n",
      "SPORK_RERUN201955KLBB 114\n",
      "SPORK_RERUN201955KDDC 115\n",
      "SPORK_RERUN201956KICT 116\n",
      "SPORK_RERUN201957KLBB 117\n",
      "SPORK_RERUN2019518KDDC 118\n",
      "SPORK_RERUN2019518KSJT 119\n",
      "SPORK_RERUN2019518KDYX 120\n",
      "SPORK_RERUN2019520KTLX 121\n",
      "SPORK_RERUN2019521KTWX 122\n",
      "SPORK_RERUN2019523KINX 123\n",
      "SPORK_RERUN2019525KLBB 124\n",
      "SPORK_RERUN2019624KSJT 125\n",
      "SPORK_RERUN2019812KGLD 126\n",
      "SPORK_RERUN2019816KTWX 127\n",
      "SPORK_RERUN2019929KILX 128\n",
      "SPORK_RERUN20191021KFWS 129\n",
      "SPORK_RERUN20191216KPOE 130\n",
      "SPORK_RERUN20191216KSHV 131\n",
      "SPORK_RERUN2019528KIWX 132\n",
      "SPORK_RERUN2019527KLOT 133\n",
      "SPORK_RERUN20191228KFDX 134\n",
      "SPORK_RERUN2019623KAMA 135\n",
      "SPORK_RERUN201974KCYS 136\n",
      "SPORK_RERUN2014428KLZK 137\n",
      "SPORK_RERUN2014429KHTX 138\n",
      "SPORK_RERUN2018720KLVX 139\n",
      "SPORK_RERUN202033KOHX 140\n",
      "SPORK_RERUN2014522KENX 141\n",
      "SPORK_RERUN2017628KDMX 142\n",
      "SPORK_RERUN2020331KMOB 143\n",
      "SPORK_RERUN2019521KMAF 144\n",
      "SPORK_RERUN202054KTLX 145\n",
      "SPORK_RERUN2020517KLCH 146\n",
      "SPORK_RERUN201562KUDX 147\n",
      "SPORK_RERUN2015716KUEX 148\n",
      "SPORK_RERUN2015716KTWX 149\n",
      "SPORK_RERUN2017326KTLX 150\n",
      "SPORK_RERUN201886KPUX 151\n",
      "SPORK_RERUN201944KFDR 152\n",
      "SPORK_RERUN2019413KDFX 153\n",
      "SPORK_RERUN2019428KGLD 154\n",
      "SPORK_RERUN201953KMAF 155\n",
      "SPORK_RERUN201955KUEX 156\n",
      "SPORK_RERUN201958KSJT 157\n",
      "SPORK_RERUN2019523KFDR 158\n",
      "SPORK_RERUN2019524KLBB 159\n",
      "SPORK_RERUN2019523KRLX 160\n",
      "SPORK_RERUN2019612KDDC 161\n",
      "SPORK_RERUN2019617KSJT 162\n",
      "SPORK_RERUN2019619KAMA 163\n",
      "SPORK_RERUN2019625KLBB 164\n",
      "SPORK_RERUN2019727KMPX 165\n",
      "SPORK_RERUN2019810KUDX 166\n",
      "SPORK_RERUN2019930KUEX 167\n",
      "SPORK_RERUN2019101KDMX 168\n",
      "SPORK_RERUN2019102KDVN 169\n",
      "SPORK_RERUN20191010KFDR 170\n",
      "SPORK_RERUN2019117KMAF 171\n",
      "SPORK_RERUN2019430KLBB 172\n",
      "SPORK_RERUN2019413KPOE 173\n",
      "SPORK_RERUN201866KFWS 174\n",
      "SPORK_RERUN2019619KINX 175\n",
      "SPORK_RERUN2019620KLNX 176\n",
      "SPORK_RERUN2019621KFTG 177\n",
      "SPORK_RERUN201974KPUX 178\n",
      "SPORK_RERUN201769KAMA 179\n",
      "SPORK_RERUN2016413KEWX 180\n",
      "SPORK_RERUN2020318KDYX 181\n",
      "SPORK_RERUN2020320KDFX 182\n",
      "SPORK_RERUN2020322KGLD 183\n",
      "SPORK_RERUN2020324KPUX 184\n",
      "SPORK_RERUN2020328KPBZ 185\n",
      "SPORK_RERUN202047KMKX 186\n",
      "SPORK_RERUN202048KRLX 187\n",
      "SPORK_RERUN2020411KDYX 188\n",
      "SPORK_RERUN2020419KLCH 189\n",
      "SPORK_RERUN2020425KSHV 190\n",
      "SPORK_RERUN2020428KTLX 191\n",
      "SPORK_RERUN202053KUDX 192\n",
      "SPORK_RERUN202058KFDR 193\n",
      "SPORK_RERUN2020512KAMA 194\n",
      "SPORK_RERUN2020522KSJT 195\n",
      "SPORK_RERUN201584KGLD 196\n",
      "SPORK_RERUN201778KGLD 197\n",
      "SPORK_RERUN2017812KLNX 198\n",
      "SPORK_RERUN201564KDDC 199\n",
      "SPORK_RERUN2018520KLBB 200\n",
      "SPORK_RERUN2020422KDYX 201\n",
      "SPORK_RERUN2020523KSRX 202\n",
      "SPORK_RERUN2020526KDFX 203\n",
      "SPORK_RERUN2020528KEWX 204\n",
      "SPORK_RERUN2020718KMPX 205\n"
     ]
    }
   ],
   "source": [
    "#for i in np.arange(0,205,1):\n",
    "for i in range(len(ALL_years)):\n",
    "\n",
    "    print('SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i]), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dfe81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(24,24))\n",
    "xr2 = np.arange(0, len(rotated_data[0]), 1)\n",
    "reflevs = np.arange(20, 70, 5)\n",
    "zdrdlev = np.arange(1, 10, 1)\n",
    "rotlev = np.arange(0.002,0.01, 0.002)\n",
    "# plt.contourf(xr, xr, ref_st[4, :, :], reflevs, cmap=pyart.graph.cm_colorblind.HomeyerRainbow)\n",
    "# plt.contour(xr, xr, zdrd_st[:, :]/4, zdrdlev, cmap=plt.cm.viridis, linewidths=5)\n",
    "plt.contourf(rotated_data[0], rotated_data[1], rotated_data[2], reflevs, cmap=pyart.graph.cm_colorblind.HomeyerRainbow)\n",
    "plt.contourf(rotated_data[0], rotated_data[1], rotated_data[7]/4, zdrdlev, cmap=plt.cm.viridis)\n",
    "plt.contour(rotated_data[0], rotated_data[1], rotated_data[3], rotlev, colors='r', linewidths=4)\n",
    "plt.contour(rotated_data[0], rotated_data[1], rotated_data[4], rotlev, colors='purple', linewidths=4)\n",
    "plt.contour(rotated_data[0], rotated_data[1], rotated_data[5], rotlev, colors='blue', linewidths=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb21cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rotated_data[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2373e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=31\n",
    "ffd_i = ffds[i]\n",
    "ncfile = Dataset('D:/NewSPORK_stamps/SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.nc')\n",
    "print('SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.nc')\n",
    "ref = ncfile.variables['REFL'][:]\n",
    "kdp = ncfile.variables['KDP'][:]\n",
    "zdr = ncfile.variables['ZDR'][:]\n",
    "cc = ncfile.variables['CC'][:]\n",
    "zdr[ref < 20] = np.nan\n",
    "zdr[cc < 0.9] = np.nan\n",
    "kdp[ref < 20] = np.nan\n",
    "kdp[cc < 0.9] = np.nan\n",
    "nzdr = ncfile.variables['NZDR'][:]\n",
    "nzdr[ref[:,4,:,:] < 20] = 0.0\n",
    "nzdr[cc[:,4,:,:] < 0.95] = 0.0\n",
    "zdrd = ncfile.variables['ZDRD'][:]\n",
    "rot = ncfile.variables['ROT'][:]\n",
    "times = ncfile.variables['Times'][:]\n",
    "azim = ncfile.variables['azim'][:]\n",
    "vel = ncfile.variables['VEL'][:]\n",
    "\n",
    "st_1 = datetime(int(ALL_years[i]), int(ALL_months[i]), int(ALL_days[i]), int(ALL_hours[i]), 0)-timedelta(minutes=30)\n",
    "print(st_1)\n",
    "time_diffs = []\n",
    "for j in range(len(times)):\n",
    "    \n",
    "    time_diff = (datetime.fromtimestamp(times[j]) - st_1).total_seconds()\n",
    "    time_diffs.append(time_diff)\n",
    "time_array = np.asarray(time_diffs)  \n",
    "time_array[time_array<0] = 9999\n",
    "print(time_array)\n",
    "print(time_diffs)\n",
    "print(np.where(time_array < 3600))\n",
    "print(ref[time_array < 3600, :, :, :].shape[0], 'times')\n",
    "\n",
    "ref_mn = ref[time_array < 3600, :, :, :]\n",
    "zdr_mn = zdr[time_array < 3600, :, :, :]\n",
    "kdp_mn = kdp[time_array < 3600, :, :, :]\n",
    "cc_mn = cc[time_array < 3600, :, :, :]\n",
    "rot_mn = rot[time_array < 3600, :, :, :]\n",
    "zdrd_mn = zdrd[time_array < 3600, :, :]\n",
    "nzdr_mn = nzdr[time_array < 3600, :, :]\n",
    "\n",
    "ref_st = np.nanmean(ref_mn, axis=0)\n",
    "zdr_st = np.nanmean(zdr_mn, axis=0)\n",
    "kdp_st = np.nanmean(kdp_mn, axis=0)\n",
    "cc_st = np.nanmean(cc_mn, axis=0)\n",
    "rot_st = np.nanmean(rot_mn, axis=0)\n",
    "zdrd_st = np.nanmean(zdrd_mn, axis=0)\n",
    "nzdr_st = np.nanmean(nzdr_mn, axis=0)\n",
    "\n",
    "nzdr_mn[np.isnan(nzdr_mn)] = 0.0\n",
    "\n",
    "ref_pm = _run_pmm_one_variable(ref_mn)\n",
    "rot_pm = _run_pmm_one_variable(rot_mn)\n",
    "zdrd_pm =  _run_pmm_one_variable(zdrd_mn)\n",
    "nzdr_pm =  _run_pmm_one_variable(nzdr_mn)\n",
    "for q in range(zdr_mn.shape[0]):\n",
    "    print(np.max(rot_mn[q,12,:,:]))\n",
    "print(ref_mn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fae5763",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zdr_mn.shape)\n",
    "print(rot_mn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61792e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(24,24))\n",
    "xr = np.arange(0, ref.shape[2], 1)\n",
    "reflevs = np.arange(20, 70, 5)\n",
    "zdrdlev = np.arange(1, 10, 1)\n",
    "rotlev = np.arange(0.002,0.01, 0.002)\n",
    "# plt.contourf(xr, xr, ref_st[4, :, :], reflevs, cmap=pyart.graph.cm_colorblind.HomeyerRainbow)\n",
    "# plt.contour(xr, xr, zdrd_st[:, :]/4, zdrdlev, cmap=plt.cm.viridis, linewidths=5)\n",
    "plt.contourf(xr, xr, ref_pm[4, :, :], reflevs, cmap=pyart.graph.cm_colorblind.HomeyerRainbow)\n",
    "plt.contour(xr, xr, zdrd_pm[:, :]/4, zdrdlev, cmap=plt.cm.viridis, linewidths=5)\n",
    "plt.contour(xr, xr, rot_pm[4, :, :], rotlev, colors='r', linewidths=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ffd_i)\n",
    "ffd_x = 190\n",
    "xr = np.arange(-70,70,1)\n",
    "xra1, yra1 = DoRotation(xr, xr, RotRad=np.deg2rad((ffd_i)-180)*-1)\n",
    "xri, yri, Z_interpi = interpolate_to_grid(np.ndarray.flatten(xra1), np.ndarray.flatten(yra1),\n",
    "                                         np.ndarray.flatten(ref_pm[4,:,:]), hres=1,\n",
    "                                         boundary_coords={'west':-50,'south':-50,'east':49,'north':49})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b113e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(24,24))\n",
    "#xr = np.arange(0, ref.shape[2], 1)\n",
    "reflevs = np.arange(20, 70, 5)\n",
    "zdrdlev = np.arange(1, 10, 1)\n",
    "rotlev = np.arange(0.002,0.01, 0.002)\n",
    "# plt.contourf(xr, xr, ref_st[4, :, :], reflevs, cmap=pyart.graph.cm_colorblind.HomeyerRainbow)\n",
    "# plt.contour(xr, xr, zdrd_st[:, :]/4, zdrdlev, cmap=plt.cm.viridis, linewidths=5)\n",
    "plt.contourf(xr, xr, ref_pm[4, :, :], reflevs, cmap=pyart.graph.cm_colorblind.HomeyerRainbow)\n",
    "plt.contour(xr, xr, zdrd_pm[:, :]/4, zdrdlev, cmap=plt.cm.viridis, linewidths=5)\n",
    "plt.contour(xr, xr, rot_pm[4, :, :], rotlev, colors='r', linewidths=5)\n",
    "#plt.scatter(yra1,xra1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb52055",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(24,24))\n",
    "xr2 = np.arange(0, len(xri), 1)\n",
    "reflevs = np.arange(20, 70, 5)\n",
    "zdrdlev = np.arange(1, 10, 1)\n",
    "rotlev = np.arange(0.002,0.01, 0.002)\n",
    "# plt.contourf(xr, xr, ref_st[4, :, :], reflevs, cmap=pyart.graph.cm_colorblind.HomeyerRainbow)\n",
    "# plt.contour(xr, xr, zdrd_st[:, :]/4, zdrdlev, cmap=plt.cm.viridis, linewidths=5)\n",
    "plt.contourf(xri, yri, Z_interpi, reflevs, cmap=pyart.graph.cm_colorblind.HomeyerRainbow)\n",
    "plt.contour(xr, xr, ref_pm[4, :, :], [40])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd5cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ffd_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8877c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Geod\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#Create geod object for later distance and area calculations\n",
    "g = Geod(ellps='sphere')\n",
    "def radar_motion(start_time, end_time, sloni, slati, slone, slate):\n",
    "\n",
    "    stormdte = (np.datetime64(end_time) - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')\n",
    "    stormdtce = datetime.utcfromtimestamp(stormdte)\n",
    "    stormdti = (np.datetime64(start_time) - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')\n",
    "    stormdtci = datetime.utcfromtimestamp(stormdti)\n",
    "\n",
    "    distance_track = g.inv(sloni, slati,\n",
    "                           slone, slate)\n",
    "    dist_track = distance_track[2]                                        \n",
    "    if distance_track[1] < 0:\n",
    "        back = distance_track[1] + 360\n",
    "    else:\n",
    "        back = distance_track[1]\n",
    "    storm_dur = stormdtce-stormdtci\n",
    "    storm_sec = storm_dur.seconds\n",
    "    speed = dist_track/storm_sec\n",
    "    direc = back\n",
    "    return speed, direc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e9b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get observed motions for all of these cases\n",
    "#Generate the file names for the postage stamps\n",
    "j=1\n",
    "new_speeds = []\n",
    "new_directions = []\n",
    "\n",
    "for i in range(len(ALL_years)):\n",
    "#for i in np.arange(201,207,1):\n",
    "#for i in [104]:\n",
    "    try:\n",
    "        print('D:/NewSPORK_stamps/SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.nc')\n",
    "        ncfile = Dataset('D:/NewSPORK_stamps/SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.nc')\n",
    "    except:\n",
    "        try:\n",
    "            ncfile = Dataset('D:/NewSPORK_stamps/SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(int(ALL_days[i])-1)+str(ALL_sites[i])+'.nc')\n",
    "        except:\n",
    "            print('SPORK_RERUN'+str(ALL_years[i])+str(ALL_months[i])+str(ALL_days[i])+str(ALL_sites[i])+'.nc is missing!')\n",
    "            print(j)\n",
    "            j=j+1\n",
    "    case_loni = ncfile.variables['Lons'][:,70,70] \n",
    "    case_lati = ncfile.variables['Lats'][:,70,70] \n",
    "    case_timesi = ncfile.variables['Times'][:] \n",
    "    #print(case_loni, case_lati, case_timesi)\n",
    "    \n",
    "    st_1 = datetime(int(ALL_years[i]), int(ALL_months[i]), int(ALL_days[i]), int(ALL_hours[i]), 0)-timedelta(minutes=30)\n",
    "    #print(st_1)\n",
    "    time_diffs = []\n",
    "    for j in range(len(case_timesi)):\n",
    "\n",
    "        time_diff = (datetime.fromtimestamp(case_timesi[j]) - st_1).total_seconds()\n",
    "        time_diffs.append(time_diff)\n",
    "    time_array = np.asarray(time_diffs)  \n",
    "    time_array[time_array<0] = 9999\n",
    "    #print(time_array)\n",
    "    #print(time_diffs)\n",
    "    #print(np.where(time_array < 3600))\n",
    "    \n",
    "    case_lon = case_loni[time_array < 3600]\n",
    "    case_lat = case_lati[time_array < 3600]\n",
    "    case_times = case_timesi[time_array < 3600]\n",
    "    \n",
    "    Xlon = np.array(case_lon)\n",
    "    Ylat = np.array(case_lat)\n",
    "    X_obs1 = Xlon[0]\n",
    "    X_obs2 = Xlon[-1]\n",
    "    X_mean = np.mean(Xlon)\n",
    "    Y_mean = np.mean(Ylat)\n",
    "    num = 0\n",
    "    den = 0\n",
    "    for i in range (len(Xlon)):\n",
    "        num += (Xlon[i] - X_mean)*(Ylat[i] - Y_mean)\n",
    "        den += (Xlon[i] - X_mean)**2\n",
    "    m = num / den\n",
    "    c = Y_mean - m*X_mean\n",
    "    Y_pred2 = m*X_obs2 + c\n",
    "    Y_pred1 = m*X_obs1 + c\n",
    "    #print(\"X_obs1, Y_pred1 =\", X_obs1, Y_pred1, \"; X_obs2, Y_pred2 =\", X_obs2, Y_pred2)\n",
    "    \n",
    "    st_speed, st_direction = radar_motion(datetime.fromtimestamp(case_times[0]), datetime.fromtimestamp(case_times[-1]), X_obs1, Y_pred1, X_obs2, Y_pred2)\n",
    "    \n",
    "    print(st_speed, st_direction)\n",
    "    \n",
    "    new_speeds.append(st_speed)\n",
    "    new_directions.append(st_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f09add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "efilename = 'OldObsMotions.csv'\n",
    "with open(efilename, mode='w') as cal_file:\n",
    "    calWriter = csv.writer(cal_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "\n",
    "for i in range(len(ALL_years)):\n",
    "\n",
    "    with open(efilename, mode='a') as cal_file:\n",
    "            calWriter = csv.writer(cal_file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "            calWriter.writerow([ALL_years[i], ALL_months[i], ALL_days[i], ALL_hours[i], new_speeds[i], new_directions[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c75e59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
